# ------------------------------------------------------
# backend/main.py
# FastAPI Backend Application
# ------------------------------------------------------

import boto3
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Dict

from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough, RunnableParallel
from langchain_core.output_parsers import StrOutputParser
from langchain_aws import ChatBedrock
from langchain_aws import AmazonKnowledgeBasesRetriever

app = FastAPI()

# CORS ì„¤ì • - Streamlitê³¼ í†µì‹ ì„ ìœ„í•´ í•„ìš”
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ì‹¤ì œ ìš´ì˜í™˜ê²½ì—ì„œëŠ” êµ¬ì²´ì ì¸ originì„ ì§€ì •í•˜ì„¸ìš”
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ------------------------------------------------------
# Amazon Bedrock - settings

bedrock_runtime = boto3.client(
    service_name="bedrock-runtime",
    region_name="us-east-1",
)

model_id = "anthropic.claude-3-haiku-20240307-v1:0"

model_kwargs = {
    "max_tokens": 2048,
    "temperature": 0.3,
    "top_k": 5,
    "top_p": 0.95,
    "stop_sequences": ["\n\nHuman"],
}

# ------------------------------------------------------
# LangChain - RAG chain with citations

prompt = PromptTemplate(
    template="""
        "task_instructions" : [

        ë‹¹ì‹ ì€ ìž¬ì • ì •ë³´ ê´€ë ¨ ì „ë¬¸ê°€ ìž…ë‹ˆë‹¤. ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— í•œ ë¬¸ìž¥ ì´ë‚´ë¡œ ë‹µë³€í•˜ì„¸ìš”.
        1. ë¬¸ì„œì— ìžˆëŠ” ë‚´ìš©ì„ ìžë¥´ê±°ë‚˜ íŽ¸ì§‘í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ê°€ì ¸ì˜¤ì„¸ìš”.
        2. ìˆœì„œì— ë”°ë¥¸ ë²ˆí˜¸ë¥¼ ë§¤ê¸°ì§€ ë§ˆì„¸ìš”. ì¶œë ¥ ì‹œ ë¶ˆì´ìµì„ ì¤„ ê²ƒìž…ë‹ˆë‹¤.
        3. ìˆ˜ì¹˜ì— ë‹¨ìœ„ê°€ ìžˆë‹¤ë©´ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì— ë‹¨ìœ„ë¥¼ í¬í•¨í•˜ì„¸ìš”.
        4. ì§ˆë¬¸ì˜ í‚¤ì›Œë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¬¸ì„œë¥¼ ëê¹Œì§€ ê²€í† í•˜ì„¸ìš”.
        5. ë‹µë³€ ì™¸ì— ì˜ˆì‹œ, ì°¸ê³ , ì •ë³´ ì¶œì²˜, ì‹ ë¢°ë„, í™•ìž¥ëœ ë‹µë³€, 'ë‹µë³€: ', 'ì°¸ê³ : 'ë¥¼ ì ˆëŒ€ë¡œ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.

        ]

        "ë¬¸ì„œ":
        {context},

        "ì§ˆë¬¸":
        {question},

        "ì£¼ì–´ì§„ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ë§Œ í•œ ë¬¸ìž¥ìœ¼ë¡œ ìƒì„±í•œë‹¤."

        "output": 
        """,
    input_variables=["context", "question"]
)

# Amazon Bedrock - KnowledgeBase Retriever 
retriever = AmazonKnowledgeBasesRetriever(
    knowledge_base_id="ZR7PIA4I4M",  # ðŸ‘ˆ Set your Knowledge base ID
    retrieval_config={"vectorSearchConfiguration": {"numberOfResults": 2}},
)

model = ChatBedrock(
    client=bedrock_runtime,
    model_id=model_id,
    model_kwargs=model_kwargs,
)

chain = (
    RunnableParallel({"context": retriever, "question": RunnablePassthrough()})
    .assign(response=prompt | model | StrOutputParser())
    .pick(["response", "context"])
)

# ------------------------------------------------------
# FastAPI routes

class ChatRequest(BaseModel):
    prompt: str

@app.post("/chat")
async def chat(request: ChatRequest) -> Dict:
    """Non-streaming chat endpoint"""
    response = chain.invoke(request.prompt)
    return response

@app.post("/chat/stream")
async def chat_stream(request: ChatRequest):
    """Streaming chat endpoint"""
    async def generate():
        for chunk in chain.stream(request.prompt):
            yield f"{chunk}\n"

    return generate()